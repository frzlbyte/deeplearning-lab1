Task 1: Fully Connected Neural Network Example:

import tensorflow as tf
from tensorflow.keras import layers, models

model_fcn = models.Sequential([
    layers.Dense(128, activation='relu', input_shape=(256,)),
    layers.Dense(64, activation='tanh'),
    layers.Dense(32, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model_fcn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_fcn.summary()

Locally Connected Network Example:

model_locally_connected_no_weights = models.Sequential([
    layers.Conv1D(128, kernel_size=5, activation='relu', input_shape=(256, 1)),  # Local connection with no weight sharing
    layers.Conv1D(64, kernel_size=5, activation='tanh'),
    layers.Conv1D(32, kernel_size=5, activation='relu'),
    layers.Flatten(),  # Flatten the output from Conv1D to Dense
    layers.Dense(10, activation='softmax')  # Output layer
])

model_locally_connected_no_weights.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_locally_connected_no_weights.summary()



Convolutional Neural Network Example:

model_cnn = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 1)),  # Conv2D to simulate local connectivity with weight sharing
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='tanh'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(10, activation='softmax')  # Output layer
])

model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_cnn.summary()
